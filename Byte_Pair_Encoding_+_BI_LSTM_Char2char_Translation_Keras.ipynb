{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Byte Pair Encoding + BI-LSTM_Char2char_Translation_Keras",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxs5-DzxwGBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8670eddc-20b4-4129-c3a8-37ed4630b779"
      },
      "source": [
        "## Split min-ind3 text file into two different text files for encoding and decoding ##\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "!pip install keras_metrics\n",
        "import keras_metrics\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%cd /content/\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "!pip install keras_metrics\n",
        "import keras_metrics\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%cd /content/\n",
        "## split text file ##\n",
        "with open('min-ind3.txt','r',encoding='utf-8') as f:\n",
        "  lines = f.read().split('\\n')\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_val,test = train_test_split(lines,test_size=0.2) # here split size can be change with test_size parameter\n",
        "with open('min-ind_test.txt','w',encoding='utf-8') as w:\n",
        "  for line in test:\n",
        "    w.write(line+'\\n')\n",
        "\n",
        "with open('min-ind_train.txt','w',encoding='utf-8') as w:\n",
        "  for line in train_val:\n",
        "    w.write(line+'\\n')\n",
        "!pip install sentencepiece\n",
        "lines_1 = []\n",
        "lines_2 = []\n",
        "with open('min-ind_train.txt','r',encoding='utf-8') as min:\n",
        "  for line in min.readlines():\n",
        "    split = line.split(',')\n",
        "    if split!=['\\n']:\n",
        "      lines_1.append(split[0])\n",
        "      lines_2.append(split[1])\n",
        "with open('min-ind_input.txt','w',encoding='utf-8') as enc_txt:\n",
        "  for line in lines_1:\n",
        "    enc_txt.write(line+'\\n')\n",
        "\n",
        "with open('min-ind_target.txt','w',encoding='utf-8') as tar_txt:\n",
        "  for line in lines_2:\n",
        "    tar_txt.write(line)\n",
        "\n",
        "import sentencepiece as spm\n",
        "model_inp = spm.SentencePieceTrainer.train(\"--input=min-ind_input.txt --model_prefix=input --vocab_size=30\")\n",
        "sp_inp = spm.SentencePieceProcessor()\n",
        "sp_inp.load('input.model')\n",
        "#import sentencepiece as spm\n",
        "model_tar = spm.SentencePieceTrainer.train(\"--input=min-ind_target.txt --model_prefix=target --vocab_size=30\")\n",
        "sp_tar = spm.SentencePieceProcessor()\n",
        "sp_tar.load('target.model')\n",
        "\n",
        "### Prepare data ###\n",
        "input_encode = []\n",
        "target_encode = []\n",
        "with open('min-ind_input.txt','r',encoding='utf-8') as inp:\n",
        "  for line in inp:\n",
        "    input_encode.append(sp_inp.encode_as_pieces(line))\n",
        "with open('min-ind_target.txt','r',encoding='utf-8') as tar:\n",
        "  for line in tar:\n",
        "    target_encode.append(['\\t']+sp_tar.encode_as_pieces(line)+['\\n'])\n",
        "\n",
        "## Create a dictionary for characters mapping ##\n",
        "input_subwords = np.unique(np.array([tk for tok in input_encode for tk in tok]))\n",
        "input_subwords = np.append(input_subwords,\" \")\n",
        "target_subwords = np.unique(np.array([tk for tok in target_encode for tk in tok]))\n",
        "target_subwords = np.append(target_subwords,\" \")\n",
        "input_token_index = dict([(char,i) for i,char in enumerate(sorted(list(input_subwords)))])\n",
        "target_token_index = dict([(char,i) for i,char in enumerate(sorted(list(target_subwords)))])\n",
        "\n",
        "num_encoder_tokens= len(input_subwords)\n",
        "num_decoder_tokens = len(target_subwords)\n",
        "\n",
        "max_encoder_seq_length = max([len(words) for words in input_encode])\n",
        "max_decoder_seq_length = max([len(words) for words in target_encode])\n",
        "\n",
        "encoder_input_data = np.zeros((len(input_encode),max_encoder_seq_length,num_encoder_tokens),dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_encode),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "decoder_target_data = np.zeros((len(target_encode),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "\n",
        "for i,(enc_word,tar_word) in enumerate(zip(input_encode,target_encode)):\n",
        "  for t,char in enumerate(enc_word):\n",
        "    encoder_input_data[i,t,input_token_index[char]] = 1.0\n",
        "  decoder_input_data[i,t+1 :,input_token_index[\" \"]] = 1.0 # encoding space at the end of encoder word for decoder input to reach to next word for encoding\n",
        "  for t,char in enumerate(tar_word):\n",
        "    decoder_input_data[i,t,target_token_index[char]] = 1.0\n",
        "    if t>0:\n",
        "      decoder_target_data[i,t-1,target_token_index[char]] = 1.0\n",
        "  decoder_input_data[i,t+1 :,target_token_index[\" \"]] = 1.0\n",
        "  decoder_target_data[i,t:,target_token_index[\" \"]] = 1.0\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras_metrics\n",
            "  Downloading https://files.pythonhosted.org/packages/32/c9/a87420da8e73de944e63a8e9cdcfb1f03ca31a7c4cdcdbd45d2cdf13275a/keras_metrics-1.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras_metrics) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras_metrics) (1.15.0)\n",
            "Installing collected packages: keras-metrics\n",
            "Successfully installed keras-metrics-1.1.0\n",
            "/content\n",
            "Requirement already satisfied: keras_metrics in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Keras>=2.1.5 in /usr/local/lib/python3.7/dist-packages (from keras_metrics) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.1.5->keras_metrics) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->Keras>=2.1.5->keras_metrics) (1.15.0)\n",
            "/content\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IjhgtYB5Tp8",
        "outputId": "d4f9f98c-393f-4a90-de41-53bf964fd1ad"
      },
      "source": [
        "## 5-fold BI-LSTM ##\n",
        "latent_dim_1 = 128\n",
        "latent_dim_2 = 256\n",
        "latent_dim_3 = 512\n",
        "kfold_acc = []\n",
        "kf = KFold(n_splits=5,random_state=96, shuffle = True) # 5 folds for training and validation sets\n",
        "save_dir = '/content/'\n",
        "fold_var = 5\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "latent_dim = 256 # edit LSTM units\n",
        "num_samples = 14032\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "kf = KFold(10)\n",
        "for i,(train_index,val_index) in enumerate(kf.split(np.zeros(len(input_encode[:11222])),decoder_target_data)):\n",
        "  print('K={}'.format(i+1))\n",
        "  encoder_inputs = keras.Input(shape=(None,num_encoder_tokens))\n",
        "  encoder_outputs,forward_h,forward_c,backward_h,backward_c= keras.layers.Bidirectional(keras.layers.LSTM(latent_dim_2, return_state=True),merge_mode='concat',name='encoder_lstm1')(encoder_inputs)\n",
        "  #encoder_outputs = encoder(encoder_inputs)\n",
        "  #print(encoder)\n",
        "  #encoder_outputs = keras.layers.Bidirectional(keras.layers.LSTM(latent_dim_2),merge_mode='concat',name='encoder_lstm2')(encoder)\n",
        "  #print(encoder_outputs)\n",
        "  #encoder_inputs = embedding_layer_input(encoder_inputs)\n",
        "  # We discard `encoder_outputs` and only keep the states.\n",
        "  state_h = tf.keras.layers.Concatenate()([forward_h,forward_c])\n",
        "  state_c = tf.keras.layers.Concatenate()([backward_h,backward_c])\n",
        "  encoder_states = [state_h,state_c] # hidden and cell state\n",
        "  # Set up the decoder, using `encoder_states` as initial state.\n",
        "  decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "  #decoder_inputs = embedding_layer_output(decoder_inputs)\n",
        "  # We set up our decoder to return full output sequences,\n",
        "  # and to return internal states as well. We don't use the\n",
        "  # return states in the training model, but we will use them in inference.\n",
        "  decoder_outputs,*decoder_states= keras.layers.LSTM(latent_dim_3, return_sequences=True, return_state=True)(decoder_inputs, initial_state=encoder_states)\n",
        "  #decoder_outputs, _, _ ,*_= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "\n",
        "  decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "  decoder_outputs = decoder_dense(decoder_outputs) \n",
        "\n",
        "  # Define the model that will turn\n",
        "  # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  encoder_input_data_t = pd.Series(list(encoder_input_data)).iloc[train_index].to_numpy()\n",
        "  decoder_input_data_t = pd.Series(list(decoder_input_data)).iloc[train_index].to_numpy()\n",
        "  decoder_target_data_t = pd.Series(list(decoder_target_data)).iloc[train_index].to_numpy()\n",
        "\n",
        "  encoder_input_data_val = pd.Series(list(encoder_input_data)).iloc[val_index].to_numpy()\n",
        "  decoder_input_data_val = pd.Series(list(decoder_input_data)).iloc[val_index].to_numpy()\n",
        "  decoder_target_data_val = pd.Series(list(decoder_target_data)).iloc[val_index].to_numpy()\n",
        "\n",
        "\n",
        "  encoder_input_data_t = np.array([list(en) for en in encoder_input_data_t])\n",
        "  decoder_input_data_t = np.array([list(en) for en in decoder_input_data_t])\n",
        "  decoder_target_data_t = np.array([list(en) for en in decoder_target_data_t])\n",
        "\n",
        "  encoder_input_data_val = np.array([list(en) for en in encoder_input_data_val])\n",
        "  decoder_input_data_val = np.array([list(en) for en in decoder_input_data_val])\n",
        "  decoder_target_data_val = np.array([list(en) for en in decoder_target_data_val])\n",
        "  x_val = [encoder_input_data_val,decoder_input_data_val]\n",
        "  y_val = decoder_target_data_val\n",
        "  model.compile(\n",
        "    optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\",keras.metrics.Recall(),keras.metrics.Precision()]\n",
        "  )\n",
        "  results = model.fit(\n",
        "      [encoder_input_data_t, decoder_input_data_t],\n",
        "      decoder_target_data_t,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      validation_data =(x_val,y_val)\n",
        "  )\n",
        "  '''\n",
        "  plt.plot(results.history['accuracy'])\n",
        "  plt.plot(results.history['val_accuracy'])\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.legend(['train','val'],loc='upper right')\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.show()\n",
        "  '''\n",
        "  model.save('model_bilstm_256_{}-Fold{}'.format(fold_var,i+1))\n",
        "  model = keras.models.load_model(\"model_bilstm_256_{}-Fold{}\".format(fold_var,i+1)) # Using 5-Fold cross validated model\n",
        "  encoder_inputs = model.input[0]  # input_1\n",
        "  encoder_outputs,state_h_enc,state_c_enc,backward_h,backward_c  = model.layers[1].output  # lstm_1\n",
        "  states_h = keras.layers.Concatenate()([state_h_enc,state_c_enc])\n",
        "  states_c = keras.layers.Concatenate()([backward_h,backward_c])\n",
        "  #print(states_h)\n",
        "  encoder_states = [states_h,states_c]\n",
        "  encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "  decoder_inputs = model.input[1]  # input_2\n",
        "  decoder_state_input_h = keras.Input(shape=(latent_dim_3,), name=\"input_3\")\n",
        "  decoder_state_input_c = keras.Input(shape=(latent_dim_3,), name=\"input_5\")\n",
        "  decoder_states_inputs = [decoder_state_input_h,decoder_state_input_c]\n",
        "  decoder_lstm = model.layers[5]\n",
        "  decoder_outputs, state_h_dec,state_c_dec = decoder_lstm(\n",
        "      decoder_inputs, initial_state=decoder_states_inputs #, \n",
        "  )\n",
        "  decoder_states = [state_h_dec,state_c_dec]\n",
        "  decoder_dense = model.layers[6]\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  decoder_model = keras.Model(\n",
        "      [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        "  )\n",
        "  # Reverse-lookup token index to decode sequences back to\n",
        "  # something readable.\n",
        "  reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "  reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "  def decode_sequence(input_seq):\n",
        "      # Encode the input as state vectors.\n",
        "      states_value = encoder_model.predict(input_seq)\n",
        "      #print(states_value)\n",
        "      target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "      # Populate the first character of target sequence with the start character.\n",
        "      target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "      stop_condition = False\n",
        "      decoded_sentence = \"\"\n",
        "      while not stop_condition:\n",
        "          output_tokens,h,c = decoder_model.predict([target_seq] + states_value)\n",
        "          # Sample a token\n",
        "         # print('output_tokens',output_tokens)\n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "          decoded_sentence += sampled_char\n",
        "          # Exit condition: either hit max length\n",
        "          # or find stop character.\n",
        "          if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "              stop_condition = True\n",
        "          # Update the target sequence (of length 1).\n",
        "          target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "          target_seq[0, 0, sampled_token_index] = 1.0\n",
        "          states_value = [h,c]\n",
        "      return decoded_sentence\n",
        "\n",
        "    ## Split min-ind3 text file into two different text files for encoding and decoding ##\n",
        "  '''\n",
        "  lines_1 = []\n",
        "  lines_2 = []\n",
        "  with open('min-ind_test.txt','r',encoding='utf-8') as min:\n",
        "    for line in min.readlines():\n",
        "      split = line.split(',')\n",
        "      if split!=['\\n']:\n",
        "        lines_1.append(split[0])\n",
        "        lines_2.append(split[1])\n",
        "  with open('min-ind_input_test.txt','w',encoding='utf-8') as enc_txt:\n",
        "    for line in lines_1:\n",
        "      enc_txt.write(line+'\\n')\n",
        "\n",
        "  with open('min-ind_target_test.txt','w',encoding='utf-8') as tar_txt:\n",
        "    for line in lines_2:\n",
        "      tar_txt.write(line)\n",
        "\n",
        "  model_inp = spm.SentencePieceTrainer.train(\"--input=min-ind_input_test.txt --model_prefix=input_test --vocab_size=30\")\n",
        "  sp_inp = spm.SentencePieceProcessor()\n",
        "  sp_inp.load('input_test.model')\n",
        "  #import sentencepiece as spm\n",
        "  model_tar = spm.SentencePieceTrainer.train(\"--input=min-ind_target_test.txt --model_prefix=target_test --vocab_size=30\")\n",
        "  sp_tar = spm.SentencePieceProcessor()\n",
        "  sp_tar.load('target_test.model')\n",
        "\n",
        "  ### Prepare data ###\n",
        "  input_encode = []\n",
        "  target_encode = []\n",
        "  with open('min-ind_input_test.txt','r',encoding='utf-8') as inp:\n",
        "    for line in inp:\n",
        "      input_encode.append(sp_inp.encode_as_pieces(line))\n",
        "  with open('min-ind_target_test.txt','r',encoding='utf-8') as tar:\n",
        "    for line in tar:\n",
        "      target_encode.append(['\\t']+sp_tar.encode_as_pieces(line)+['\\n'])\n",
        "\n",
        "  ## Create a dictionary for characters mapping ##\n",
        "  \n",
        "  input_subwords = np.unique(np.array([tk for tok in input_encode for tk in tok]))\n",
        "  input_subwords = np.append(input_subwords,\" \")\n",
        "  target_subwords = np.unique(np.array([tk for tok in target_encode for tk in tok]))\n",
        "  target_subwords = np.append(target_subwords,\" \")\n",
        "  input_token_index = dict([(char,i) for i,char in enumerate(sorted(list(input_subwords)))])\n",
        "  target_token_index = dict([(char,i) for i,char in enumerate(sorted(list(target_subwords)))])\n",
        "  \n",
        "  num_encoder_tokens= len(input_subwords)\n",
        "  num_decoder_tokens = len(target_subwords)\n",
        "\n",
        "  max_encoder_seq_length = max([len(words) for words in input_encode])\n",
        "  max_decoder_seq_length = max([len(words) for words in target_encode])\n",
        "\n",
        "  encoder_input_data = np.zeros((len(input_encode),max_encoder_seq_length,num_encoder_tokens),dtype='float32')\n",
        "  decoder_input_data = np.zeros((len(input_encode),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "  decoder_target_data = np.zeros((len(target_encode),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "  \n",
        "  \n",
        "  for i,(enc_word,tar_word) in enumerate(zip(input_encode,target_encode)):\n",
        "    for t,char in enumerate(enc_word):\n",
        "      encoder_input_data[i,t,input_token_index[char]] = 1.0\n",
        "    \n",
        "    decoder_input_data[i,t+1 :,input_token_index[\" \"]] = 1.0 # encoding space at the end of encoder word for decoder input to reach to next word for encoding\n",
        "    for t,char in enumerate(tar_word):\n",
        "      decoder_input_data[i,t,target_token_index[char]] = 1.0\n",
        "      if t>0:\n",
        "        decoder_target_data[i,t-1,target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i,t+1 :,target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i,t:,target_token_index[\" \"]] = 1.0\n",
        "    \n",
        "    \n",
        "  \n",
        "  save_dir = '/content/'\n",
        "  #fold_var = 10\n",
        "  #batch_size = 128\n",
        "  #epochs = 25\n",
        "  latent_dim = 256 # edit LSTM units\n",
        "  num_samples = 14032\n",
        "  data_path = 'min-ind_test.txt'\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  #input_characters = set()\n",
        "  #target_characters = set()\n",
        "  with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "  print('lines',lines[:len(lines)])\n",
        "  print(len(lines))\n",
        "  for line in lines[:num_samples]:\n",
        "    if len(line.split(','))==2:\n",
        "      input_text, target_text = line.split(\",\")\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    \n",
        "  '''\n",
        "  '''\n",
        "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "      for t, char in enumerate(input_text):\n",
        "          encoder_input_data[i, t-1, input_token_index[char]] = 1.0\n",
        "  '''\n",
        "  '''\n",
        "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "      for t, char in enumerate(input_text):\n",
        "          encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "      decoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "      for t, char in enumerate(target_text):\n",
        "          # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "          decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "          if t > 0:\n",
        "              # decoder_target_data will be ahead by one timestep\n",
        "              # and will not include the start character.\n",
        "              decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "      decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "      decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "  '''\n",
        "  \n",
        "  df = pd.DataFrame()\n",
        "  input_texts_ls = []\n",
        "  decoded_sentences_ls = []\n",
        "  target_texts_ls = []\n",
        "  for seq_index in range(50):\n",
        "      # Take one sequence (part of the training set)\n",
        "      # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "      #print(input_seq)\n",
        "    decoded_sentence= decode_sequence(input_seq)\n",
        "    #input_texts_ls.append(np.array(input_encode)[seq_index].replace(\"\\t\", \"\").replace(\"\\n\", \"\"))\n",
        "    #target_texts_ls.append(np.array(target_encode)[seq_index].replace(\"\\t\", \"\").replace(\"\\n\", \"\"))\n",
        "    #decoded_sentences_ls.append(decoded_sentence.replace(\"\\t\", \"\").replace(\"\\n\", \"\"))\n",
        "    #print(type(input_texts_ls))\n",
        "    #print(\"-\")\n",
        "    print(\"Input sentence:\", ''.join(input_encode[seq_index]))\n",
        "    print(\"Decoded sentence:\", ''.join(decoded_sentence))\n",
        "    print(\"Target sentence:\", ''.join(target_encode[seq_index]))\n",
        "  #temp_list = [input_texts_ls, target_texts_ls, decoded_sentences_ls]\n",
        "  \n",
        "  #df = pd.DataFrame(temp_list).transpose()\n",
        "  #df = df.rename(columns={0: 'input_text', 1: 'target_text', 2:'decode_sentence'})\n",
        "  #print(df)\n",
        "  #df_csv = df.to_csv('Input_decoded_sentences_5-fold-{}.csv'.format(i))\n",
        "  ## Split min-ind3 text file into two different text files for encoding and decoding ##\n",
        "  '''\n",
        "  lines_1 = []\n",
        "  lines_2 = []\n",
        "  with open('min-ind_train.txt','r',encoding='utf-8') as min:\n",
        "    for line in min.readlines():\n",
        "      split = line.split(',')\n",
        "      if split!=['\\n']:\n",
        "        lines_1.append(split[0])\n",
        "        lines_2.append(split[1])\n",
        "  with open('min-ind_input.txt','w',encoding='utf-8') as enc_txt:\n",
        "    for line in lines_1:\n",
        "      enc_txt.write(line+'\\n')\n",
        "\n",
        "  with open('min-ind_target.txt','w',encoding='utf-8') as tar_txt:\n",
        "    for line in lines_2:\n",
        "      tar_txt.write(line)\n",
        "\n",
        "  import sentencepiece as spm\n",
        "  model_inp = spm.SentencePieceTrainer.train(\"--input=min-ind_input.txt --model_prefix=input --vocab_size=30\")\n",
        "  sp_inp = spm.SentencePieceProcessor()\n",
        "  sp_inp.load('input.model')\n",
        "  #import sentencepiece as spm\n",
        "  model_tar = spm.SentencePieceTrainer.train(\"--input=min-ind_target.txt --model_prefix=target --vocab_size=30\")\n",
        "  sp_tar = spm.SentencePieceProcessor()\n",
        "  sp_tar.load('target.model')\n",
        "\n",
        "  ### Prepare data ###\n",
        "  input_encode = []\n",
        "  target_encode = []\n",
        "  with open('min-ind_input.txt','r',encoding='utf-8') as inp:\n",
        "    for line in inp:\n",
        "      input_encode.append(sp_inp.encode_as_pieces(line))\n",
        "  with open('min-ind_target.txt','r',encoding='utf-8') as tar:\n",
        "    for line in tar:\n",
        "      target_encode.append(['\\t']+sp_tar.encode_as_pieces(line)+['\\n'])\n",
        "\n",
        "  ## Create a dictionary for characters mapping ##\n",
        "  input_subwords = np.unique(np.array([tk for tok in input_encode for tk in tok]))\n",
        "  input_subwords = np.append(input_subwords,\" \")\n",
        "  target_subwords = np.unique(np.array([tk for tok in target_encode for tk in tok]))\n",
        "  target_subwords = np.append(target_subwords,\" \")\n",
        "  input_token_index = dict([(char,i) for i,char in enumerate(sorted(list(input_subwords)))])\n",
        "  target_token_index = dict([(char,i) for i,char in enumerate(sorted(list(target_subwords)))])\n",
        "\n",
        "  num_encoder_tokens= len(input_subwords)\n",
        "  num_decoder_tokens = len(target_subwords)\n",
        "\n",
        "  max_encoder_seq_length = max([len(words) for words in input_encode])\n",
        "  max_decoder_seq_length = max([len(words) for words in target_encode])\n",
        "\n",
        "  encoder_input_data = np.zeros((len(input_encode),max_encoder_seq_length,num_encoder_tokens),dtype='float32')\n",
        "  decoder_input_data = np.zeros((len(input_encode),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "  decoder_target_data = np.zeros((len(target_encode),max_decoder_seq_length,num_decoder_tokens),dtype='float32')\n",
        "\n",
        "  for i,(enc_word,tar_word) in enumerate(zip(input_encode,target_encode)):\n",
        "    for t,char in enumerate(enc_word):\n",
        "      encoder_input_data[i,t,input_token_index[char]] = 1.0\n",
        "    decoder_input_data[i,t+1 :,input_token_index[\" \"]] = 1.0 # encoding space at the end of encoder word for decoder input to reach to next word for encoding\n",
        "    for t,char in enumerate(tar_word):\n",
        "      decoder_input_data[i,t,target_token_index[char]] = 1.0\n",
        "      if t>0:\n",
        "        decoder_target_data[i,t-1,target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i,t+1 :,target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i,t:,target_token_index[\" \"]] = 1.0\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  data_path = 'min-ind_train.txt'\n",
        "  input_texts = []\n",
        "  target_texts = []\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "  with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "    #print('lines',lines)\n",
        "  print('lines',lines[:len(lines)])\n",
        "  print(len(lines))\n",
        "  for line in lines[:num_samples]:\n",
        "    if len(line.split(','))==2:\n",
        "      input_text, target_text = line.split(\",\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "  input_characters.add(':')\n",
        "  target_characters.add('-')\n",
        "  input_characters = sorted(list(input_characters))\n",
        "  target_characters = sorted(list(target_characters))\n",
        "  num_encoder_tokens = len(input_characters)\n",
        "  num_decoder_tokens = len(target_characters)\n",
        "  max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "  max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "  '''\n",
        "  '''\n",
        "  input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "  target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "  encoder_input_data = np.zeros(\n",
        "      (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "  decoder_input_data = np.zeros(\n",
        "      (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "  decoder_target_data = np.zeros(\n",
        "      (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        "  )\n",
        "\n",
        "  for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "      for t, char in enumerate(input_text):\n",
        "          encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "      decoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "      for t, char in enumerate(target_text):\n",
        "          # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "          decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "          if t > 0:\n",
        "              # decoder_target_data will be ahead by one timestep\n",
        "              # and will not include the start character.\n",
        "              decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "      decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "      decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n",
        "  '''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K=1\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 39s 69ms/step - loss: 1.9247 - accuracy: 0.5696 - recall: 0.4195 - precision: 0.8768 - val_loss: 1.1186 - val_accuracy: 0.6857 - val_recall: 0.5948 - val_precision: 0.9835\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0922 - accuracy: 0.6910 - recall: 0.5996 - precision: 0.9772 - val_loss: 0.9541 - val_accuracy: 0.7287 - val_recall: 0.6331 - val_precision: 0.9932\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.9374 - accuracy: 0.7284 - recall: 0.6388 - precision: 0.9889 - val_loss: 0.8665 - val_accuracy: 0.7397 - val_recall: 0.6556 - val_precision: 0.9831\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8710 - accuracy: 0.7372 - recall: 0.6544 - precision: 0.9791 - val_loss: 0.8215 - val_accuracy: 0.7505 - val_recall: 0.6660 - val_precision: 0.9801\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8312 - accuracy: 0.7450 - recall: 0.6662 - precision: 0.9717 - val_loss: 0.7994 - val_accuracy: 0.7567 - val_recall: 0.6747 - val_precision: 0.9743\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8151 - accuracy: 0.7477 - recall: 0.6703 - precision: 0.9699 - val_loss: 0.7859 - val_accuracy: 0.7591 - val_recall: 0.6740 - val_precision: 0.9736\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7956 - accuracy: 0.7526 - recall: 0.6730 - precision: 0.9709 - val_loss: 0.7680 - val_accuracy: 0.7656 - val_recall: 0.6829 - val_precision: 0.9686\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7859 - accuracy: 0.7536 - recall: 0.6777 - precision: 0.9675 - val_loss: 0.7523 - val_accuracy: 0.7740 - val_recall: 0.6862 - val_precision: 0.9676\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7804 - accuracy: 0.7565 - recall: 0.6785 - precision: 0.9663 - val_loss: 0.7333 - val_accuracy: 0.7771 - val_recall: 0.6851 - val_precision: 0.9699\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7624 - accuracy: 0.7614 - recall: 0.6816 - precision: 0.9668 - val_loss: 0.7246 - val_accuracy: 0.7804 - val_recall: 0.6903 - val_precision: 0.9620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_3_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold1/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold1/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁peratangan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁pertendangan\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁peranggang\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁diperakat\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁peratangan\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁kerasatan\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁pertenangan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁menyambungkan\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perakat\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁perakat\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikatakan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakat\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁peratangan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁menyambungkan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁perakat\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁pertenangan\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menyambungkan\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁menyampukan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁menyambungkan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁teratang\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁menyambungkan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=2\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 10s 64ms/step - loss: 1.9230 - accuracy: 0.5700 - recall_1: 0.4220 - precision_1: 0.8752 - val_loss: 1.1150 - val_accuracy: 0.6739 - val_recall_1: 0.6135 - val_precision_1: 0.9466\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.1047 - accuracy: 0.6886 - recall_1: 0.5990 - precision_1: 0.9685 - val_loss: 0.9508 - val_accuracy: 0.7274 - val_recall_1: 0.6342 - val_precision_1: 0.9946\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.9379 - accuracy: 0.7279 - recall_1: 0.6388 - precision_1: 0.9874 - val_loss: 0.8608 - val_accuracy: 0.7463 - val_recall_1: 0.6634 - val_precision_1: 0.9826\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8716 - accuracy: 0.7367 - recall_1: 0.6551 - precision_1: 0.9770 - val_loss: 0.8157 - val_accuracy: 0.7486 - val_recall_1: 0.6715 - val_precision_1: 0.9784\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8294 - accuracy: 0.7444 - recall_1: 0.6660 - precision_1: 0.9718 - val_loss: 0.7940 - val_accuracy: 0.7573 - val_recall_1: 0.6812 - val_precision_1: 0.9716\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8150 - accuracy: 0.7469 - recall_1: 0.6702 - precision_1: 0.9693 - val_loss: 0.7761 - val_accuracy: 0.7592 - val_recall_1: 0.6799 - val_precision_1: 0.9752\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7946 - accuracy: 0.7520 - recall_1: 0.6745 - precision_1: 0.9693 - val_loss: 0.7605 - val_accuracy: 0.7643 - val_recall_1: 0.6889 - val_precision_1: 0.9689\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7844 - accuracy: 0.7540 - recall_1: 0.6768 - precision_1: 0.9666 - val_loss: 0.7430 - val_accuracy: 0.7690 - val_recall_1: 0.6885 - val_precision_1: 0.9695\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7766 - accuracy: 0.7565 - recall_1: 0.6784 - precision_1: 0.9667 - val_loss: 0.7275 - val_accuracy: 0.7744 - val_recall_1: 0.6861 - val_precision_1: 0.9741\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7602 - accuracy: 0.7614 - recall_1: 0.6814 - precision_1: 0.9658 - val_loss: 0.7146 - val_accuracy: 0.7832 - val_recall_1: 0.6953 - val_precision_1: 0.9658\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_11_layer_call_fn, lstm_cell_11_layer_call_and_return_conditional_losses, lstm_cell_9_layer_call_fn, lstm_cell_9_layer_call_and_return_conditional_losses, lstm_cell_10_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold2/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold2/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁kemenangan\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁dikatakan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁bertarat\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁bertakat\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁dikatakan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁diperakatkan\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁bertakat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁menyabatkan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁serata\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berkatang\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁bertakat\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁bertakat\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikerakatkan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakatkan\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁menyabatkan\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁bertakat\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁keratangan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁serata\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁bertakat\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁kerakatan\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kerakatan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁serata\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁menyambangkan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=3\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 65ms/step - loss: 1.9352 - accuracy: 0.5713 - recall_2: 0.4163 - precision_2: 0.8751 - val_loss: 1.0881 - val_accuracy: 0.6940 - val_recall_2: 0.6057 - val_precision_2: 0.9876\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0760 - accuracy: 0.6981 - recall_2: 0.6048 - precision_2: 0.9797 - val_loss: 0.9379 - val_accuracy: 0.7286 - val_recall_2: 0.6369 - val_precision_2: 0.9980\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 43ms/step - loss: 0.9399 - accuracy: 0.7270 - recall_2: 0.6378 - precision_2: 0.9875 - val_loss: 0.8535 - val_accuracy: 0.7447 - val_recall_2: 0.6515 - val_precision_2: 0.9907\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8672 - accuracy: 0.7387 - recall_2: 0.6559 - precision_2: 0.9776 - val_loss: 0.8141 - val_accuracy: 0.7533 - val_recall_2: 0.6704 - val_precision_2: 0.9780\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8294 - accuracy: 0.7446 - recall_2: 0.6659 - precision_2: 0.9720 - val_loss: 0.7968 - val_accuracy: 0.7542 - val_recall_2: 0.6835 - val_precision_2: 0.9686\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8107 - accuracy: 0.7491 - recall_2: 0.6712 - precision_2: 0.9710 - val_loss: 0.7719 - val_accuracy: 0.7635 - val_recall_2: 0.6760 - val_precision_2: 0.9778\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7952 - accuracy: 0.7515 - recall_2: 0.6741 - precision_2: 0.9694 - val_loss: 0.7506 - val_accuracy: 0.7716 - val_recall_2: 0.6852 - val_precision_2: 0.9706\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7812 - accuracy: 0.7565 - recall_2: 0.6784 - precision_2: 0.9670 - val_loss: 0.7389 - val_accuracy: 0.7733 - val_recall_2: 0.6857 - val_precision_2: 0.9737\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.7737 - accuracy: 0.7585 - recall_2: 0.6781 - precision_2: 0.9671 - val_loss: 0.7264 - val_accuracy: 0.7770 - val_recall_2: 0.6921 - val_precision_2: 0.9663\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7634 - accuracy: 0.7616 - recall_2: 0.6800 - precision_2: 0.9657 - val_loss: 0.7113 - val_accuracy: 0.7876 - val_recall_2: 0.6942 - val_precision_2: 0.9649\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_18_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_19_layer_call_fn, lstm_cell_19_layer_call_and_return_conditional_losses, lstm_cell_17_layer_call_fn, lstm_cell_17_layer_call_and_return_conditional_losses, lstm_cell_18_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold3/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold3/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁kemenangan\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁diperatahkan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁sembalah\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁selatah\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁kelangkan\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁diperatahkan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁kemalahan\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁keratahan\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁sembalah\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁keranggangan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbadang\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁menarakan\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁diperatahkan\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperatahkan\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁menarakan\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁kerangkan\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁kemangkan\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁kemalahan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerangkan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁teranggat\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menarakan\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berberangkat\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁berbatah\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁sembat\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁menarakan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁kemalahan\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁menarakan\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁dikatarkan\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kemalahan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁teratah\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁menarakan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=4\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 65ms/step - loss: 1.9419 - accuracy: 0.5786 - recall_3: 0.4157 - precision_3: 0.8774 - val_loss: 1.1215 - val_accuracy: 0.6753 - val_recall_3: 0.6026 - val_precision_3: 0.9671\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0853 - accuracy: 0.6962 - recall_3: 0.6039 - precision_3: 0.9810 - val_loss: 0.9498 - val_accuracy: 0.7255 - val_recall_3: 0.6422 - val_precision_3: 0.9887\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.9435 - accuracy: 0.7249 - recall_3: 0.6362 - precision_3: 0.9867 - val_loss: 0.8651 - val_accuracy: 0.7430 - val_recall_3: 0.6469 - val_precision_3: 0.9921\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 43ms/step - loss: 0.8682 - accuracy: 0.7379 - recall_3: 0.6552 - precision_3: 0.9787 - val_loss: 0.8160 - val_accuracy: 0.7527 - val_recall_3: 0.6675 - val_precision_3: 0.9789\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8325 - accuracy: 0.7435 - recall_3: 0.6646 - precision_3: 0.9729 - val_loss: 0.7958 - val_accuracy: 0.7549 - val_recall_3: 0.6797 - val_precision_3: 0.9705\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8132 - accuracy: 0.7491 - recall_3: 0.6704 - precision_3: 0.9714 - val_loss: 0.7695 - val_accuracy: 0.7627 - val_recall_3: 0.6767 - val_precision_3: 0.9773\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7967 - accuracy: 0.7520 - recall_3: 0.6742 - precision_3: 0.9698 - val_loss: 0.7473 - val_accuracy: 0.7717 - val_recall_3: 0.6825 - val_precision_3: 0.9737\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7835 - accuracy: 0.7551 - recall_3: 0.6770 - precision_3: 0.9680 - val_loss: 0.7359 - val_accuracy: 0.7731 - val_recall_3: 0.6860 - val_precision_3: 0.9736\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7747 - accuracy: 0.7579 - recall_3: 0.6787 - precision_3: 0.9672 - val_loss: 0.7226 - val_accuracy: 0.7762 - val_recall_3: 0.6889 - val_precision_3: 0.9696\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 43ms/step - loss: 0.7661 - accuracy: 0.7611 - recall_3: 0.6785 - precision_3: 0.9667 - val_loss: 0.7099 - val_accuracy: 0.7875 - val_recall_3: 0.6958 - val_precision_3: 0.9612\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_27_layer_call_fn, lstm_cell_27_layer_call_and_return_conditional_losses, lstm_cell_25_layer_call_fn, lstm_cell_25_layer_call_and_return_conditional_losses, lstm_cell_26_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold4/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold4/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁menambakan\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁diperakatan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁kemalahan\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁semata\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁dibarakan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁penangkan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kerangkan\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁sembat\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁diberakan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁perangkatan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁diberakan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakatan\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁penangkatan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perangkatan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerangkan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁terakat\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menambangkan\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁berang\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁sembal\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁penangkatan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁membatakan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁terakat\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁menambangkan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁menambakan\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁menambakan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁diserakan\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁terakat\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁menambakan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁sembal\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menangkat\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perangkatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁menambakan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=5\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 64ms/step - loss: 1.9277 - accuracy: 0.5719 - recall_4: 0.4190 - precision_4: 0.8797 - val_loss: 1.1468 - val_accuracy: 0.6872 - val_recall_4: 0.5815 - val_precision_4: 0.9813\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0861 - accuracy: 0.6954 - recall_4: 0.6019 - precision_4: 0.9792 - val_loss: 0.9698 - val_accuracy: 0.7236 - val_recall_4: 0.6277 - val_precision_4: 0.9961\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.9375 - accuracy: 0.7279 - recall_4: 0.6402 - precision_4: 0.9871 - val_loss: 0.8944 - val_accuracy: 0.7328 - val_recall_4: 0.6454 - val_precision_4: 0.9820\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.8637 - accuracy: 0.7406 - recall_4: 0.6571 - precision_4: 0.9782 - val_loss: 0.8573 - val_accuracy: 0.7360 - val_recall_4: 0.6537 - val_precision_4: 0.9787\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8269 - accuracy: 0.7469 - recall_4: 0.6659 - precision_4: 0.9740 - val_loss: 0.8344 - val_accuracy: 0.7438 - val_recall_4: 0.6675 - val_precision_4: 0.9650\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8048 - accuracy: 0.7528 - recall_4: 0.6716 - precision_4: 0.9719 - val_loss: 0.8199 - val_accuracy: 0.7479 - val_recall_4: 0.6698 - val_precision_4: 0.9656\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7868 - accuracy: 0.7574 - recall_4: 0.6762 - precision_4: 0.9695 - val_loss: 0.8076 - val_accuracy: 0.7529 - val_recall_4: 0.6773 - val_precision_4: 0.9593\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.7682 - accuracy: 0.7633 - recall_4: 0.6804 - precision_4: 0.9666 - val_loss: 0.7999 - val_accuracy: 0.7538 - val_recall_4: 0.6750 - val_precision_4: 0.9620\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7547 - accuracy: 0.7676 - recall_4: 0.6838 - precision_4: 0.9652 - val_loss: 0.7967 - val_accuracy: 0.7541 - val_recall_4: 0.6761 - val_precision_4: 0.9589\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7434 - accuracy: 0.7709 - recall_4: 0.6845 - precision_4: 0.9640 - val_loss: 0.7924 - val_accuracy: 0.7582 - val_recall_4: 0.6799 - val_precision_4: 0.9560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_35_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses, lstm_cell_33_layer_call_fn, lstm_cell_33_layer_call_and_return_conditional_losses, lstm_cell_34_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_35_layer_call_fn, lstm_cell_35_layer_call_and_return_conditional_losses, lstm_cell_33_layer_call_fn, lstm_cell_33_layer_call_and_return_conditional_losses, lstm_cell_34_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold5/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold5/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁dipentangkan\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁komonomisi\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁disembatkan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁pembataan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁sembat\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁terat\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁terang\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁dibalakan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁pengatangan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁perumusan\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁selamat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁sempor\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁selamatan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbatah\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁perumusan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁kemalian\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perikatan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁dilembatkan\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikerangkan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakatikan\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁mengatakan\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁kematian\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁perumusan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁memangkat\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁menyembatkan\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁kelamatan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁keramatan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁teratah\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁membalah\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berbelah\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁keberangan\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁semata\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁peruntangan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁memperisikan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁kemataan\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁mentembatkan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁semasi\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁pemberahan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁sisi\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁sematah\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁seratah\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁pemberahan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁sembat\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menyambatkan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁membatikan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=6\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 12s 83ms/step - loss: 1.9341 - accuracy: 0.5771 - recall_5: 0.4158 - precision_5: 0.8818 - val_loss: 1.1538 - val_accuracy: 0.6671 - val_recall_5: 0.5974 - val_precision_5: 0.9551\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 4s 46ms/step - loss: 1.0915 - accuracy: 0.6928 - recall_5: 0.6019 - precision_5: 0.9800 - val_loss: 0.9715 - val_accuracy: 0.7157 - val_recall_5: 0.6272 - val_precision_5: 0.9867\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.9369 - accuracy: 0.7273 - recall_5: 0.6383 - precision_5: 0.9887 - val_loss: 0.8839 - val_accuracy: 0.7349 - val_recall_5: 0.6498 - val_precision_5: 0.9794\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.8577 - accuracy: 0.7429 - recall_5: 0.6579 - precision_5: 0.9782 - val_loss: 0.8498 - val_accuracy: 0.7395 - val_recall_5: 0.6583 - val_precision_5: 0.9767\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8203 - accuracy: 0.7506 - recall_5: 0.6659 - precision_5: 0.9737 - val_loss: 0.8287 - val_accuracy: 0.7426 - val_recall_5: 0.6725 - val_precision_5: 0.9602\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.7974 - accuracy: 0.7559 - recall_5: 0.6722 - precision_5: 0.9720 - val_loss: 0.8171 - val_accuracy: 0.7461 - val_recall_5: 0.6740 - val_precision_5: 0.9634\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7810 - accuracy: 0.7588 - recall_5: 0.6760 - precision_5: 0.9695 - val_loss: 0.8114 - val_accuracy: 0.7447 - val_recall_5: 0.6728 - val_precision_5: 0.9631\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7590 - accuracy: 0.7670 - recall_5: 0.6825 - precision_5: 0.9662 - val_loss: 0.8250 - val_accuracy: 0.7406 - val_recall_5: 0.6783 - val_precision_5: 0.9511\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 4s 45ms/step - loss: 0.7409 - accuracy: 0.7737 - recall_5: 0.6870 - precision_5: 0.9620 - val_loss: 0.8260 - val_accuracy: 0.7416 - val_recall_5: 0.6811 - val_precision_5: 0.9457\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.7241 - accuracy: 0.7797 - recall_5: 0.6902 - precision_5: 0.9609 - val_loss: 0.8286 - val_accuracy: 0.7442 - val_recall_5: 0.6839 - val_precision_5: 0.9418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_42_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_43_layer_call_fn, lstm_cell_43_layer_call_and_return_conditional_losses, lstm_cell_41_layer_call_fn, lstm_cell_41_layer_call_and_return_conditional_losses, lstm_cell_42_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold6/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold6/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁kemenangan\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁diperakan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁seburu\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁tersembat\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁selatar\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁diparakan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁serangga\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁pengangkatan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kupur\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁sebara\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁sebasi\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁peratahan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbasasan\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁perberahan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁membarkan\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perikitan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁dilentakan\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikasurkan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakat\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁mengarak\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁terang\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁peruput\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁membasikan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁sebang\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁kerajahan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerakatan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁terah\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menalah\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berberataran\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁berbakat\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁sebata\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁perangkatan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁mempintakan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁terunya\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁menterasi\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁memburikan\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁pererangan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁sisi\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kemasaan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁teratah\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁pembalahan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁sebang\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menambangkan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁memberakan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=7\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 66ms/step - loss: 1.9094 - accuracy: 0.5773 - recall_6: 0.4206 - precision_6: 0.8812 - val_loss: 1.1504 - val_accuracy: 0.6892 - val_recall_6: 0.5793 - val_precision_6: 0.9823\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0864 - accuracy: 0.6948 - recall_6: 0.6018 - precision_6: 0.9814 - val_loss: 0.9657 - val_accuracy: 0.7197 - val_recall_6: 0.6307 - val_precision_6: 0.9949\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.9300 - accuracy: 0.7286 - recall_6: 0.6411 - precision_6: 0.9881 - val_loss: 0.8909 - val_accuracy: 0.7312 - val_recall_6: 0.6484 - val_precision_6: 0.9801\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8555 - accuracy: 0.7425 - recall_6: 0.6602 - precision_6: 0.9779 - val_loss: 0.8595 - val_accuracy: 0.7362 - val_recall_6: 0.6562 - val_precision_6: 0.9769\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.8187 - accuracy: 0.7497 - recall_6: 0.6676 - precision_6: 0.9739 - val_loss: 0.8348 - val_accuracy: 0.7402 - val_recall_6: 0.6682 - val_precision_6: 0.9659\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7998 - accuracy: 0.7530 - recall_6: 0.6718 - precision_6: 0.9710 - val_loss: 0.8265 - val_accuracy: 0.7422 - val_recall_6: 0.6687 - val_precision_6: 0.9657\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 4s 44ms/step - loss: 0.7818 - accuracy: 0.7582 - recall_6: 0.6759 - precision_6: 0.9694 - val_loss: 0.8221 - val_accuracy: 0.7398 - val_recall_6: 0.6686 - val_precision_6: 0.9666\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7639 - accuracy: 0.7637 - recall_6: 0.6809 - precision_6: 0.9659 - val_loss: 0.8278 - val_accuracy: 0.7410 - val_recall_6: 0.6718 - val_precision_6: 0.9596\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7439 - accuracy: 0.7723 - recall_6: 0.6860 - precision_6: 0.9625 - val_loss: 0.8324 - val_accuracy: 0.7405 - val_recall_6: 0.6761 - val_precision_6: 0.9522\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7237 - accuracy: 0.7792 - recall_6: 0.6900 - precision_6: 0.9604 - val_loss: 0.8288 - val_accuracy: 0.7411 - val_recall_6: 0.6766 - val_precision_6: 0.9485\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_51_layer_call_fn, lstm_cell_51_layer_call_and_return_conditional_losses, lstm_cell_49_layer_call_fn, lstm_cell_49_layer_call_and_return_conditional_losses, lstm_cell_50_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_51_layer_call_fn, lstm_cell_51_layer_call_and_return_conditional_losses, lstm_cell_49_layer_call_fn, lstm_cell_49_layer_call_and_return_conditional_losses, lstm_cell_50_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold7/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold7/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁beranggang\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁komen\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁disatakan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁serukun\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁terasi\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁kerataran\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁diatarkan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁jara\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁pengangkat\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kupur\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁selabat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁seperasi\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁keratahan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbara\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁peruasaan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁merakat\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perikitan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁berata\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikambakkan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakat\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁mengarak\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁terakat\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁perukutan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁mengamaskan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁sembang\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakat\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁keranggaran\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerajaran\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁teratah\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menalah\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berberatar\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁kerakan\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁serang\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁perukusan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁mempintikan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁turunya\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁memberakan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁inisi\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁perambal\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁sisi\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kemasa\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁seratar\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁sempol\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menyambakan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁mengarap\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=8\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 64ms/step - loss: 1.9254 - accuracy: 0.5754 - recall_7: 0.4200 - precision_7: 0.8787 - val_loss: 1.1567 - val_accuracy: 0.6672 - val_recall_7: 0.5994 - val_precision_7: 0.9418\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0928 - accuracy: 0.6917 - recall_7: 0.6013 - precision_7: 0.9760 - val_loss: 0.9890 - val_accuracy: 0.7201 - val_recall_7: 0.6141 - val_precision_7: 0.9968\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 43ms/step - loss: 0.9359 - accuracy: 0.7279 - recall_7: 0.6384 - precision_7: 0.9897 - val_loss: 0.9003 - val_accuracy: 0.7293 - val_recall_7: 0.6499 - val_precision_7: 0.9735\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8613 - accuracy: 0.7412 - recall_7: 0.6586 - precision_7: 0.9779 - val_loss: 0.8627 - val_accuracy: 0.7384 - val_recall_7: 0.6589 - val_precision_7: 0.9717\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8246 - accuracy: 0.7476 - recall_7: 0.6661 - precision_7: 0.9736 - val_loss: 0.8457 - val_accuracy: 0.7385 - val_recall_7: 0.6660 - val_precision_7: 0.9680\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8012 - accuracy: 0.7527 - recall_7: 0.6720 - precision_7: 0.9711 - val_loss: 0.8372 - val_accuracy: 0.7397 - val_recall_7: 0.6713 - val_precision_7: 0.9589\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7846 - accuracy: 0.7576 - recall_7: 0.6765 - precision_7: 0.9693 - val_loss: 0.8346 - val_accuracy: 0.7371 - val_recall_7: 0.6686 - val_precision_7: 0.9620\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 43ms/step - loss: 0.7636 - accuracy: 0.7651 - recall_7: 0.6813 - precision_7: 0.9652 - val_loss: 0.8371 - val_accuracy: 0.7387 - val_recall_7: 0.6730 - val_precision_7: 0.9550\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7481 - accuracy: 0.7709 - recall_7: 0.6846 - precision_7: 0.9631 - val_loss: 0.8338 - val_accuracy: 0.7385 - val_recall_7: 0.6715 - val_precision_7: 0.9552\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7326 - accuracy: 0.7762 - recall_7: 0.6872 - precision_7: 0.9620 - val_loss: 0.8414 - val_accuracy: 0.7372 - val_recall_7: 0.6724 - val_precision_7: 0.9497\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_59_layer_call_fn, lstm_cell_59_layer_call_and_return_conditional_losses, lstm_cell_57_layer_call_fn, lstm_cell_57_layer_call_and_return_conditional_losses, lstm_cell_58_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_59_layer_call_fn, lstm_cell_59_layer_call_and_return_conditional_losses, lstm_cell_57_layer_call_fn, lstm_cell_57_layer_call_and_return_conditional_losses, lstm_cell_58_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold8/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold8/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁dilamakan\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁kolomisi\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁disatikan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁pengambahan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁sentur\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁terberasi\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁mengatakan\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁diatah\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kebutukan\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁selabat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁perakaman\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁sisisi\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁disitikan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbakat\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁perbudahan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁menambakan\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perikisikan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁dilisikan\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikamatkan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakatkan\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁mengabatkan\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁kerintikan\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁perukusan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁mengatakan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁penggalian\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁kelakatan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerajahan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁terahat\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menalah\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berberasi\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁berbaka\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁serisi\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁pencubukan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁membatikan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁turinya\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁meneratikan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁siminya\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁peranggatan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁disikatikan\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kemasahan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁seratah\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁pengambahan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁sendilis\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menyambakan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁mengarakan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=9\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 65ms/step - loss: 1.9290 - accuracy: 0.5840 - recall_8: 0.4197 - precision_8: 0.8798 - val_loss: 1.1512 - val_accuracy: 0.6777 - val_recall_8: 0.5948 - val_precision_8: 0.9563\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0802 - accuracy: 0.6963 - recall_8: 0.6029 - precision_8: 0.9801 - val_loss: 0.9760 - val_accuracy: 0.7189 - val_recall_8: 0.6325 - val_precision_8: 0.9847\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.9268 - accuracy: 0.7295 - recall_8: 0.6422 - precision_8: 0.9883 - val_loss: 0.9009 - val_accuracy: 0.7275 - val_recall_8: 0.6514 - val_precision_8: 0.9716\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8582 - accuracy: 0.7420 - recall_8: 0.6602 - precision_8: 0.9781 - val_loss: 0.8603 - val_accuracy: 0.7363 - val_recall_8: 0.6562 - val_precision_8: 0.9743\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8223 - accuracy: 0.7488 - recall_8: 0.6674 - precision_8: 0.9739 - val_loss: 0.8445 - val_accuracy: 0.7392 - val_recall_8: 0.6693 - val_precision_8: 0.9588\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7981 - accuracy: 0.7540 - recall_8: 0.6743 - precision_8: 0.9709 - val_loss: 0.8351 - val_accuracy: 0.7399 - val_recall_8: 0.6709 - val_precision_8: 0.9581\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7809 - accuracy: 0.7588 - recall_8: 0.6774 - precision_8: 0.9688 - val_loss: 0.8246 - val_accuracy: 0.7398 - val_recall_8: 0.6708 - val_precision_8: 0.9595\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7669 - accuracy: 0.7632 - recall_8: 0.6804 - precision_8: 0.9662 - val_loss: 0.8348 - val_accuracy: 0.7377 - val_recall_8: 0.6685 - val_precision_8: 0.9596\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7475 - accuracy: 0.7698 - recall_8: 0.6850 - precision_8: 0.9649 - val_loss: 0.8352 - val_accuracy: 0.7389 - val_recall_8: 0.6768 - val_precision_8: 0.9500\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7315 - accuracy: 0.7766 - recall_8: 0.6884 - precision_8: 0.9596 - val_loss: 0.8406 - val_accuracy: 0.7397 - val_recall_8: 0.6797 - val_precision_8: 0.9425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_67_layer_call_fn, lstm_cell_67_layer_call_and_return_conditional_losses, lstm_cell_65_layer_call_fn, lstm_cell_65_layer_call_and_return_conditional_losses, lstm_cell_66_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_67_layer_call_fn, lstm_cell_67_layer_call_and_return_conditional_losses, lstm_cell_65_layer_call_fn, lstm_cell_65_layer_call_and_return_conditional_losses, lstm_cell_66_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold9/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold9/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁diperahasi\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁kenama\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁diserakan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁perambungan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁kenukuan\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁teralis\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁terata\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁disarahan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁berakaran\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁pengatakan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kerukusan\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁peranggangan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁selakat\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁perakasan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁semasi\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁kesisian\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbasah\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁perakasan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁merakasi\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perikatan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁dilentakan\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dikumuskan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakasi\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁kendangan\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁perukusan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁mengasaskan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁penganggangan\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakaran\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁kerasaran\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerajaran\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁terahat\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menalakan\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berakar\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁berbakatan\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁sembat\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁penangkatan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁memberakan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁penturahan\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁meneratkan\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁menisikan\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁peremasan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁disisikan\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kemasaan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁teratah\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁perimbihan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁kenalisan\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menambungkan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakaian\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁merakarkan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n",
            "K=10\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 11s 65ms/step - loss: 1.9073 - accuracy: 0.5732 - recall_9: 0.4224 - precision_9: 0.8774 - val_loss: 1.1485 - val_accuracy: 0.6743 - val_recall_9: 0.6004 - val_precision_9: 0.9469\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 1.0858 - accuracy: 0.6939 - recall_9: 0.6030 - precision_9: 0.9769 - val_loss: 0.9700 - val_accuracy: 0.7221 - val_recall_9: 0.6348 - val_precision_9: 0.9864\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.9268 - accuracy: 0.7286 - recall_9: 0.6410 - precision_9: 0.9874 - val_loss: 0.8841 - val_accuracy: 0.7338 - val_recall_9: 0.6564 - val_precision_9: 0.9744\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8570 - accuracy: 0.7409 - recall_9: 0.6594 - precision_9: 0.9777 - val_loss: 0.8571 - val_accuracy: 0.7373 - val_recall_9: 0.6686 - val_precision_9: 0.9630\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.8212 - accuracy: 0.7484 - recall_9: 0.6668 - precision_9: 0.9724 - val_loss: 0.8372 - val_accuracy: 0.7396 - val_recall_9: 0.6680 - val_precision_9: 0.9709\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7975 - accuracy: 0.7533 - recall_9: 0.6723 - precision_9: 0.9713 - val_loss: 0.8258 - val_accuracy: 0.7434 - val_recall_9: 0.6709 - val_precision_9: 0.9636\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7825 - accuracy: 0.7577 - recall_9: 0.6761 - precision_9: 0.9686 - val_loss: 0.8149 - val_accuracy: 0.7434 - val_recall_9: 0.6734 - val_precision_9: 0.9645\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7704 - accuracy: 0.7616 - recall_9: 0.6796 - precision_9: 0.9653 - val_loss: 0.8198 - val_accuracy: 0.7426 - val_recall_9: 0.6738 - val_precision_9: 0.9648\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7509 - accuracy: 0.7682 - recall_9: 0.6834 - precision_9: 0.9643 - val_loss: 0.8209 - val_accuracy: 0.7392 - val_recall_9: 0.6727 - val_precision_9: 0.9624\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 3s 44ms/step - loss: 0.7359 - accuracy: 0.7736 - recall_9: 0.6861 - precision_9: 0.9614 - val_loss: 0.8211 - val_accuracy: 0.7410 - val_recall_9: 0.6790 - val_precision_9: 0.9528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_75_layer_call_fn, lstm_cell_75_layer_call_and_return_conditional_losses, lstm_cell_73_layer_call_fn, lstm_cell_73_layer_call_and_return_conditional_losses, lstm_cell_74_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_75_layer_call_fn, lstm_cell_75_layer_call_and_return_conditional_losses, lstm_cell_73_layer_call_fn, lstm_cell_73_layer_call_and_return_conditional_losses, lstm_cell_74_layer_call_fn while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold10/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_bilstm_256_5-Fold10/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input sentence: ▁hilang\n",
            "Decoded sentence: ▁diamasi\n",
            "\n",
            "Target sentence: \t▁hilang\n",
            "\n",
            "Input sentence: ▁ekonomis\n",
            "Decoded sentence: ▁kolomonisisisi\n",
            "\n",
            "Target sentence: \t▁ekonomis\n",
            "\n",
            "Input sentence: ▁d\n",
            "Decoded sentence: ▁disamatkan\n",
            "\n",
            "Target sentence: \t▁d\n",
            "\n",
            "Input sentence: ▁pamacik\n",
            "Decoded sentence: ▁perambatan\n",
            "\n",
            "Target sentence: \t▁pemegang\n",
            "\n",
            "Input sentence: ▁sekunder\n",
            "Decoded sentence: ▁sekata\n",
            "\n",
            "Target sentence: \t▁sekunder\n",
            "\n",
            "Input sentence: ▁televisi\n",
            "Decoded sentence: ▁kelatisan\n",
            "\n",
            "Target sentence: \t▁televisi\n",
            "\n",
            "Input sentence: ▁gletser\n",
            "Decoded sentence: ▁kerasatan\n",
            "\n",
            "Target sentence: \t▁gletser\n",
            "\n",
            "Input sentence: ▁adiah\n",
            "Decoded sentence: ▁diamatkan\n",
            "\n",
            "Target sentence: \t▁hadiah\n",
            "\n",
            "Input sentence: ▁fajar\n",
            "Decoded sentence: ▁berasah\n",
            "\n",
            "Target sentence: \t▁fajar\n",
            "\n",
            "Input sentence: ▁panangkok\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁penangkap\n",
            "\n",
            "Input sentence: ▁kupu\n",
            "Decoded sentence: ▁kurus\n",
            "\n",
            "Target sentence: \t▁kupu\n",
            "\n",
            "Input sentence: ▁pangembangan\n",
            "Decoded sentence: ▁peranggatan\n",
            "\n",
            "Target sentence: \t▁pengembangan\n",
            "\n",
            "Input sentence: ▁saleba\n",
            "Decoded sentence: ▁selalah\n",
            "\n",
            "Target sentence: \t▁selebar\n",
            "\n",
            "Input sentence: ▁pamakaiannyo\n",
            "Decoded sentence: ▁perambatan\n",
            "\n",
            "Target sentence: \t▁pemakaiannya\n",
            "\n",
            "Input sentence: ▁sinopsis\n",
            "Decoded sentence: ▁sempat\n",
            "\n",
            "Target sentence: \t▁sinopsis\n",
            "\n",
            "Input sentence: ▁hadits\n",
            "Decoded sentence: ▁disisikan\n",
            "\n",
            "Target sentence: \t▁hadits\n",
            "\n",
            "Input sentence: ▁kabebasan\n",
            "Decoded sentence: ▁berbatasan\n",
            "\n",
            "Target sentence: \t▁kebebasan\n",
            "\n",
            "Input sentence: ▁purba\n",
            "Decoded sentence: ▁peramatan\n",
            "\n",
            "Target sentence: \t▁purba\n",
            "\n",
            "Input sentence: ▁rahmaik\n",
            "Decoded sentence: ▁merambatkan\n",
            "\n",
            "Target sentence: \t▁rahmat\n",
            "\n",
            "Input sentence: ▁pai▁piknik\n",
            "Decoded sentence: ▁perikatan\n",
            "\n",
            "Target sentence: \t▁wisata\n",
            "\n",
            "Input sentence: ▁leiden\n",
            "Decoded sentence: ▁diseratikan\n",
            "\n",
            "Target sentence: \t▁leiden\n",
            "\n",
            "Input sentence: ▁indak▁mujarab\n",
            "Decoded sentence: ▁dibarakan\n",
            "\n",
            "Target sentence: \t▁basi\n",
            "\n",
            "Input sentence: ▁dipaliharo\n",
            "Decoded sentence: ▁diperakati\n",
            "\n",
            "Target sentence: \t▁dipelihara\n",
            "\n",
            "Input sentence: ▁gramatikal\n",
            "Decoded sentence: ▁berakat\n",
            "\n",
            "Target sentence: \t▁gramatikal\n",
            "\n",
            "Input sentence: ▁aktifnyo\n",
            "Decoded sentence: ▁kenatakan\n",
            "\n",
            "Target sentence: \t▁aktifnya\n",
            "\n",
            "Input sentence: ▁pupuk\n",
            "Decoded sentence: ▁perukutan\n",
            "\n",
            "Target sentence: \t▁pupuk\n",
            "\n",
            "Input sentence: ▁games\n",
            "Decoded sentence: ▁kerasahan\n",
            "\n",
            "Target sentence: \t▁games\n",
            "\n",
            "Input sentence: ▁gosong\n",
            "Decoded sentence: ▁perasasan\n",
            "\n",
            "Target sentence: \t▁gosong\n",
            "\n",
            "Input sentence: ▁parilaku\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perilaku\n",
            "\n",
            "Input sentence: ▁kalahiaran\n",
            "Decoded sentence: ▁kelamatan\n",
            "\n",
            "Target sentence: \t▁kelahiran\n",
            "\n",
            "Input sentence: ▁karajo\n",
            "Decoded sentence: ▁kerasahan\n",
            "\n",
            "Target sentence: \t▁terobosan\n",
            "\n",
            "Input sentence: ▁at\n",
            "Decoded sentence: ▁teratah\n",
            "\n",
            "Target sentence: \t▁at\n",
            "\n",
            "Input sentence: ▁mal\n",
            "Decoded sentence: ▁menalasi\n",
            "\n",
            "Target sentence: \t▁mal\n",
            "\n",
            "Input sentence: ▁laboratorium\n",
            "Decoded sentence: ▁berberatahan\n",
            "\n",
            "Target sentence: \t▁laboratorium\n",
            "\n",
            "Input sentence: ▁kebajikan\n",
            "Decoded sentence: ▁berbatas\n",
            "\n",
            "Target sentence: \t▁kebajikan\n",
            "\n",
            "Input sentence: ▁sagitigo\n",
            "Decoded sentence: ▁serata\n",
            "\n",
            "Target sentence: \t▁segitiga\n",
            "\n",
            "Input sentence: ▁puncak\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁puncak\n",
            "\n",
            "Input sentence: ▁mimpi\n",
            "Decoded sentence: ▁memberakan\n",
            "\n",
            "Target sentence: \t▁mimpi\n",
            "\n",
            "Input sentence: ▁yaitunyo\n",
            "Decoded sentence: ▁turus\n",
            "\n",
            "Target sentence: \t▁yaitu\n",
            "\n",
            "Input sentence: ▁meteor\n",
            "Decoded sentence: ▁menarat\n",
            "\n",
            "Target sentence: \t▁meteor\n",
            "\n",
            "Input sentence: ▁simin\n",
            "Decoded sentence: ▁insi\n",
            "\n",
            "Target sentence: \t▁semen\n",
            "\n",
            "Input sentence: ▁perlembagaan\n",
            "Decoded sentence: ▁perambatan\n",
            "\n",
            "Target sentence: \t▁perlembagaan\n",
            "\n",
            "Input sentence: ▁irisan\n",
            "Decoded sentence: ▁indisi\n",
            "\n",
            "Target sentence: \t▁irisan\n",
            "\n",
            "Input sentence: ▁kasamaan\n",
            "Decoded sentence: ▁kerasahan\n",
            "\n",
            "Target sentence: \t▁kesamaan\n",
            "\n",
            "Input sentence: ▁strata\n",
            "Decoded sentence: ▁seratat\n",
            "\n",
            "Target sentence: \t▁strata\n",
            "\n",
            "Input sentence: ▁pamiliahan\n",
            "Decoded sentence: ▁perambatan\n",
            "\n",
            "Target sentence: \t▁pemilihan\n",
            "\n",
            "Input sentence: ▁nasionalis\n",
            "Decoded sentence: ▁selasi\n",
            "\n",
            "Target sentence: \t▁nasionalis\n",
            "\n",
            "Input sentence: ▁nam\n",
            "Decoded sentence: ▁menambatkan\n",
            "\n",
            "Target sentence: \t▁nam\n",
            "\n",
            "Input sentence: ▁parikanan\n",
            "Decoded sentence: ▁perakatan\n",
            "\n",
            "Target sentence: \t▁perikanan\n",
            "\n",
            "Input sentence: ▁mikroorganisme\n",
            "Decoded sentence: ▁memberasikan\n",
            "\n",
            "Target sentence: \t▁mikroorganisme\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}