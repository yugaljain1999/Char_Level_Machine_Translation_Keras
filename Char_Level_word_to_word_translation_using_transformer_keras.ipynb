{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Char Transformer keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPDKx6bo3FBB"
      },
      "source": [
        "!pip install keras-transformer\n",
        "import keras_transformer\n",
        "from keras_transformer import get_model,decode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZlPwt6p4J4Q",
        "outputId": "857a11d2-f42b-4a45-ea40-25078acede8e"
      },
      "source": [
        "%cd /content/drive/MyDrive/\n",
        "import pandas as pd\n",
        "with open('min-ind3.txt','r') as file:\n",
        "  source_tokens = []\n",
        "  target_tokens = []\n",
        "  for f in file.readlines():\n",
        "    f = f.replace('\\n','')\n",
        "    #print(list(f))\n",
        "    ls_source = []\n",
        "    ls_source.append(f.split(',')[0])\n",
        "    source_tokens.append(ls_source)\n",
        "    ls_target = []\n",
        "    ls_target.append(f.split(',')[1])\n",
        "    target_tokens.append(ls_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPFweXnR8g1A"
      },
      "source": [
        "## Here to test we are using just 10 samples out of 14013 samples ##\n",
        "## TO TRAIN ON WHOLE DATA IT WILL TAKE TIME SO COMMENT DOWN BELOW TWO LINES TO TRAIN ON WHOLE DATA ##\n",
        "### Split target and source tokens ###\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(source_tokens,target_tokens,test_size = 0.2)\n",
        "x_train,x_val,y_train,y_val = train_test_split(x_train,y_train,test_size = 0.25)\n",
        "target_tokens = x_train[:10]\n",
        "source_tokens = y_train[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dwI2ZoO03V9Z",
        "outputId": "049325e0-8955-4d57-d218-de41acfb59ac"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "%matplotlib inline\n",
        "#from sklearn.model_selection import KFold\n",
        "#kf = KFold(n_splits=5)\n",
        "# Generate dictionaries\n",
        "def build_token_dict(token_list):\n",
        "    token_dict = {\n",
        "        '<PAD>': 0,\n",
        "        '<START>': 1,\n",
        "        '<END>': 2,\n",
        "    }\n",
        "    for tokens in token_list:\n",
        "        for token in tokens:\n",
        "            if token not in token_dict:\n",
        "                token_dict[token] = len(token_dict)\n",
        "    return token_dict\n",
        "\n",
        "source_token_dict = build_token_dict(source_tokens)\n",
        "target_token_dict = build_token_dict(target_tokens)\n",
        "target_token_dict_inv = {v: k for k, v in target_token_dict.items()}\n",
        "\n",
        "# Add special tokens\n",
        "encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
        "decode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
        "output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
        "\n",
        "# Padding\n",
        "source_max_len = max(map(len, encode_tokens))\n",
        "target_max_len = max(map(len, decode_tokens))\n",
        "\n",
        "encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
        "decode_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decode_tokens]\n",
        "output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
        "\n",
        "encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
        "decode_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decode_tokens]\n",
        "decode_output = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n",
        "\n",
        "# Build & fit model\n",
        "model = get_model(\n",
        "    token_num=max(len(source_token_dict), len(target_token_dict)),\n",
        "    embed_dim=32,\n",
        "    encoder_num=2,\n",
        "    decoder_num=2,\n",
        "    head_num=4,\n",
        "    hidden_dim=128,\n",
        "    dropout_rate=0.05,\n",
        "    use_same_embed=False,  # Use different embeddings for different languages\n",
        ")\n",
        "model.compile('adam', 'sparse_categorical_crossentropy',metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "#encode_input_val = pd\n",
        "\n",
        "results = model.fit(\n",
        "    x=[np.array(encode_input * 1024), np.array(decode_input * 1024)],\n",
        "    y=np.array(decode_output * 1024),\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.25\n",
        ")\n",
        "plt.plot(results.history['accuracy'])\n",
        "plt.plot(results.history['val_accuracy'])\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "#plt.legend(['train','val'],loc='upper right')\n",
        "plt.title('Model Accuracy')\n",
        "plt.show()\n",
        "\n",
        "model.save('char_transformer_f')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Encoder-Input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Token-Embedding (Embedd [(None, None, 32), ( 416         Encoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-Embedding (TrigPosEmbed (None, None, 32)     0           Encoder-Token-Embedding[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     4224        Encoder-Embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-Embedding[0][0]          \n",
            "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-MultiHeadSelfAttentio (None, None, 32)     64          Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward (FeedForw (None, None, 32)     8352        Encoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Dropout ( (None, None, 32)     0           Encoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Add (Add) (None, None, 32)     0           Encoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-1-FeedForward-Norm (Lay (None, None, 32)     64          Encoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     4224        Encoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Input (InputLayer)      [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Token-Embedding (Embedd [(None, None, 32), ( 416         Decoder-Input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Encoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Embedding (TrigPosEmbed (None, None, 32)     0           Decoder-Token-Embedding[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-MultiHeadSelfAttentio (None, None, 32)     64          Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     4224        Decoder-Embedding[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward (FeedForw (None, None, 32)     8352        Encoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-1-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Dropout ( (None, None, 32)     0           Encoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-Embedding[0][0]          \n",
            "                                                                 Decoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Add (Add) (None, None, 32)     0           Encoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadSelfAttentio (None, None, 32)     64          Decoder-1-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Encoder-2-FeedForward-Norm (Lay (None, None, 32)     64          Encoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     4224        Decoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-1-MultiHeadSelfAttention-\n",
            "                                                                 Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-MultiHeadQueryAttenti (None, None, 32)     64          Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward (FeedForw (None, None, 32)     8352        Decoder-1-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward-Dropout ( (None, None, 32)     0           Decoder-1-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward-Add (Add) (None, None, 32)     0           Decoder-1-MultiHeadQueryAttention\n",
            "                                                                 Decoder-1-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-1-FeedForward-Norm (Lay (None, None, 32)     64          Decoder-1-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     4224        Decoder-1-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-2-MultiHeadSelfAttention[\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     0           Decoder-1-FeedForward-Norm[0][0] \n",
            "                                                                 Decoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadSelfAttentio (None, None, 32)     64          Decoder-2-MultiHeadSelfAttention-\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     4224        Decoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Encoder-2-FeedForward-Norm[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     0           Decoder-2-MultiHeadSelfAttention-\n",
            "                                                                 Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-MultiHeadQueryAttenti (None, None, 32)     64          Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward (FeedForw (None, None, 32)     8352        Decoder-2-MultiHeadQueryAttention\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward-Dropout ( (None, None, 32)     0           Decoder-2-FeedForward[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward-Add (Add) (None, None, 32)     0           Decoder-2-MultiHeadQueryAttention\n",
            "                                                                 Decoder-2-FeedForward-Dropout[0][\n",
            "__________________________________________________________________________________________________\n",
            "Decoder-2-FeedForward-Norm (Lay (None, None, 32)     64          Decoder-2-FeedForward-Add[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "Decoder-Output (EmbeddingSim)   (None, None, 13)     13          Decoder-2-FeedForward-Norm[0][0] \n",
            "                                                                 Decoder-Token-Embedding[0][1]    \n",
            "==================================================================================================\n",
            "Total params: 60,237\n",
            "Trainable params: 60,237\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "240/240 [==============================] - 13s 24ms/step - loss: 1.4914 - accuracy: 0.5774 - val_loss: 0.2707 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.1398 - accuracy: 1.0000 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "240/240 [==============================] - 3s 12ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 8.4709e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "240/240 [==============================] - 3s 12ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 6.3060e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 8.0311e-04 - accuracy: 1.0000 - val_loss: 4.8306e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "240/240 [==============================] - 3s 13ms/step - loss: 6.1964e-04 - accuracy: 1.0000 - val_loss: 3.7881e-04 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: char_transformer_f/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrnFgv6igDWu"
      },
      "source": [
        "# Testing data #\n",
        "source_tokens = x_test[:10]\n",
        "target_tokens = y_test[:10]\n",
        "source_token_dict = build_token_dict(source_tokens)\n",
        "target_token_dict = build_token_dict(target_tokens)\n",
        "target_token_dict_inv = {v: k for k, v in target_token_dict.items()}\n",
        "\n",
        "# Add special tokens\n",
        "encode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in source_tokens]\n",
        "decode_tokens = [['<START>'] + tokens + ['<END>'] for tokens in target_tokens]\n",
        "output_tokens = [tokens + ['<END>', '<PAD>'] for tokens in target_tokens]\n",
        "\n",
        "# Padding\n",
        "source_max_len = max(map(len, encode_tokens))\n",
        "target_max_len = max(map(len, decode_tokens))\n",
        "\n",
        "encode_tokens = [tokens + ['<PAD>'] * (source_max_len - len(tokens)) for tokens in encode_tokens]\n",
        "decode_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in decode_tokens]\n",
        "output_tokens = [tokens + ['<PAD>'] * (target_max_len - len(tokens)) for tokens in output_tokens]\n",
        "\n",
        "encode_input = [list(map(lambda x: source_token_dict[x], tokens)) for tokens in encode_tokens]\n",
        "decode_input = [list(map(lambda x: target_token_dict[x], tokens)) for tokens in decode_tokens]\n",
        "decode_output = [list(map(lambda x: [target_token_dict[x]], tokens)) for tokens in output_tokens]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbCqFujfDgOc",
        "outputId": "afc21305-a9a8-4ee2-c1a4-4053cf704273"
      },
      "source": [
        "#model = keras.models.load_model('char_transformer_f')\n",
        "# Predict\n",
        "decoded = decode(\n",
        "    model,\n",
        "    encode_input,\n",
        "    start_token=target_token_dict['<START>'],\n",
        "    end_token=target_token_dict['<END>'],\n",
        "    pad_token=target_token_dict['<PAD>'],\n",
        ")\n",
        "print(''.join(map(lambda x: target_token_dict_inv[x], decoded[0][1:-1]))) # first word in list of source tokens\n",
        "print(''.join(map(lambda x: target_token_dict_inv[x], decoded[9][1:-1]))) # second word in list of source tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "asteroid\n",
            "menorehkan\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tky5NOJDge--"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}